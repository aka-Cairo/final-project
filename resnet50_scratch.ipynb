{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##You will need a CUDA enabled GPU installed to run this code##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matt\\anaconda3\\envs\\final_project\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Matt\\anaconda3\\envs\\final_project\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.19373972814345192\n",
      "Epoch 2, Loss: 0.18269072642140355\n",
      "Epoch 3, Loss: 0.17879800540758362\n",
      "Epoch 4, Loss: 0.17785667213248024\n",
      "Epoch 5, Loss: 0.17585511859638472\n",
      "Epoch 6, Loss: 0.1744772382608965\n",
      "Epoch 7, Loss: 0.17419039109285842\n",
      "Epoch 8, Loss: 0.17447147835442361\n",
      "Epoch 9, Loss: 0.1727143205332418\n",
      "Epoch 10, Loss: 0.17239151094505129\n",
      "Validation Accuracy: 1328.609625668449%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import ast\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the CSV file\n",
    "labels_df = pd.read_csv('encoded_labels.csv')\n",
    "\n",
    "# Columns in your CSV\n",
    "file_column = 'index'  # Replace with your actual filename column name\n",
    "label_column = 'labels'  # Replace with your actual labels column name\n",
    "\n",
    "# Directory where your images are stored\n",
    "image_directory = './images/'  # Ensure this path ends with a '/'\n",
    "\n",
    "# Function to convert string representation to list of integers\n",
    "def parse_labels(label_str):\n",
    "    # Replace spaces with commas to create a valid Python list string\n",
    "    label_str = label_str.replace(' ', ',')\n",
    "    # Use ast.literal_eval to safely evaluate the string to a list\n",
    "    return list(map(int, ast.literal_eval(label_str)))\n",
    "\n",
    "# Create full paths to images and parse labels\n",
    "image_paths = [os.path.join(image_directory, fname) for fname in labels_df[file_column]]\n",
    "labels = [parse_labels(label) for label in labels_df[label_column]]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths,\n",
    "    labels,\n",
    "    test_size=0.2,  # 20% for validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)  # Multi-label classification\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')  # Convert grayscale to RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                # Resize to 224x224, standard input size for ResNet\n",
    "    transforms.ToTensor(),                        # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomDataset(train_image_paths, train_labels, transform=transform)\n",
    "val_dataset = CustomDataset(val_image_paths, val_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the modified ResNet-50 model for grayscale images\n",
    "class ModifiedResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedResNet, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 14)  # Number of classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = ModifiedResNet().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy per class: [0.893048107624054, 0.9795008897781372, 0.9554367065429688, 0.9723707437515259, 0.8832442164421082, 0.9759358167648315, 0.98128342628479, 0.9973261952400208, 0.8262032270431519, 0.9509803652763367, 0.9483066201210022, 0.9777183532714844, 0.9893048405647278, 0.9554367065429688]\n",
      "Average Validation Accuracy: 94.90069150924683%\n"
     ]
    }
   ],
   "source": [
    "# Validation loop\n",
    "model.eval()\n",
    "total_samples = len(val_loader.dataset)\n",
    "correct_samples = torch.zeros(14, dtype=torch.int)  # Assuming 14 labels/classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        predictions = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "        predicted_labels = (predictions > 0.5).float()\n",
    "\n",
    "        # For each label, count how many labels are correctly predicted\n",
    "        for i in range(14):  # Loop over the 14 pathologies\n",
    "            correct_samples[i] += (predicted_labels[:, i] == labels[:, i]).sum().item()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "accuracy_per_class = correct_samples / total_samples\n",
    "average_accuracy = accuracy_per_class.mean().item()\n",
    "\n",
    "print(f'Validation Accuracy per class: {accuracy_per_class.tolist()}')\n",
    "print(f'Average Validation Accuracy: {100 * average_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet50_scratch.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
